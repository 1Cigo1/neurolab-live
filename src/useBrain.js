import { useState, useEffect, useRef } from 'react';
import * as tf from '@tensorflow/tfjs';

export const useBrain = (architecture) => {
  const [weights, setWeights] = useState([]); 
  const [loss, setLoss] = useState(null); 
  const [isTraining, setIsTraining] = useState(false);
  const [predictions, setPredictions] = useState([]); 

  const modelRef = useRef(null);

  useEffect(() => {
    // Eski modeli temizle (Memory Leak Ã¶nlemi)
    if(modelRef.current) modelRef.current.dispose();

    const model = tf.sequential();
    
    architecture.forEach((neuronCount, index) => {
      // GiriÅŸ katmanÄ±nÄ± (0. index) atlÄ±yoruz, o sadece veri tutucudur
      if (index === 0) return; 
      
      const prevNeurons = architecture[index - 1];

      model.add(tf.layers.dense({
        units: neuronCount,
        inputShape: index === 1 ? [prevNeurons] : undefined,
        
        // --- KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°K BURADA ---
        // Ã‡Ä±kÄ±ÅŸ katmanÄ± (Sonuncusu) her zaman 'sigmoid' (0 ile 1 arasÄ± sonuÃ§ iÃ§in) olmalÄ±.
        // Ama ara katmanlarÄ± 'relu' yerine 'tanh' yaptÄ±k. 
        // 'tanh' bu tarz kÃ¼Ã§Ã¼k aÄŸlarda nÃ¶ronlarÄ±n Ã¶lmesini engeller ve 0.5 sorununu Ã§Ã¶zer.
        activation: index === architecture.length - 1 ? 'sigmoid' : 'tanh',
        
        useBias: true,
        
        // 'tanh' iÃ§in en iyi baÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±ÄŸÄ± 'glorotNormal'dir.
        // Bu, aÄŸÄ±rlÄ±klarÄ±n baÅŸtan dengeli daÄŸÄ±lmasÄ±nÄ± saÄŸlar.
        kernelInitializer: 'glorotNormal' 
      }));
    });

    // Optimizer'Ä± biraz daha agresif yaptÄ±m (0.03 -> 0.1)
    // Bu sayede takÄ±lmadan hÄ±zlÄ±ca Ã¶ÄŸrenir.
    model.compile({ 
        optimizer: tf.train.adam(0.05), 
        loss: 'meanSquaredError' 
    });
    
    modelRef.current = model;
    
    extractData(model);
    runPrediction(model);

  }, [architecture]);

  const extractData = async (model) => {
    const newWeights = [];
    for (let i = 0; i < model.layers.length; i++) {
      const layer = model.layers[i];
      const wTensor = layer.getWeights()[0]; 
      if(wTensor) {
        const wData = await wTensor.array(); 
        newWeights.push(wData);
      }
    }
    setWeights(newWeights);
  };

  const runPrediction = async (model) => {
    const xs = tf.tensor2d([[0,0], [0,1], [1,0], [1,1]]);
    const predsTensor = model.predict(xs);
    const predsData = await predsTensor.data(); 
    setPredictions(Array.from(predsData));
    xs.dispose(); predsTensor.dispose();
  };

  const train = async (learningRate, selectedTargets, onLog) => {
    if(!modelRef.current) return;
    setIsTraining(true);

    if(onLog) onLog(`âš¡ SÄ°STEM BAÅLATILIYOR... LR: ${learningRate}`);

    const xs = tf.tensor2d([[0,0], [0,1], [1,0], [1,1]]);
    const ys = tf.tensor2d(selectedTargets.map(t => [t])); 

    // KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi hÄ±zÄ± uygula
    modelRef.current.compile({ 
      optimizer: tf.train.adam(parseFloat(learningRate)), 
      loss: 'meanSquaredError' 
    });

    // DÃ¶ngÃ¼yÃ¼ artÄ±rdÄ±m ki daha kararlÄ± Ã¶ÄŸrensin
    const totalEpochs = 60;

    for (let i = 0; i < totalEpochs; i++) { 
      // shuffle: true -> Verileri karÄ±ÅŸtÄ±rarak ezberi bozar
      const h = await modelRef.current.fit(xs, ys, { epochs: 1, shuffle: true });
      const currentLoss = h.history.loss[0].toFixed(5);
      
      setLoss(currentLoss);
      
      if (i % 5 === 0) { 
        await extractData(modelRef.current);
        await runPrediction(modelRef.current);
        
        let message = `Epoch ${i}/${totalEpochs} >> Hata: ${currentLoss}`;
        if (i === 0) message = `ğŸš€ Ä°LK TUR: AÄŸÄ±rlÄ±klar dengeleniyor...`;
        else if (currentLoss > 0.24 && currentLoss < 0.26) message = `âš ï¸ DÄ°KKAT: KararsÄ±z BÃ¶lge (0.50)`;
        else if (currentLoss < 0.1) message = `âœ… BAÅARILI: Ã‡Ã¶zÃ¼me yaklaÅŸÄ±ldÄ±.`;
        
        if(onLog) onLog(message);
        await new Promise(r => setTimeout(r, 10)); 
      }
    }
    
    if(onLog) onLog(`ğŸ EÄÄ°TÄ°M BÄ°TTÄ°. Son Hata: ${loss}`);
    
    await extractData(modelRef.current);
    await runPrediction(modelRef.current);

    setIsTraining(false);
    xs.dispose(); ys.dispose(); 
  };

  return { weights, loss, isTraining, predictions, train };
};